{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Afra17/BootCamp_Sdaia_DL_W4/blob/main/Project_Wee4_SDAIA_DL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# **Medina Landmark Classification: ViT Fine-Tuning & LoRA**\n"
      ],
      "metadata": {
        "id": "ZuFuJiUA06YN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fQFF7QCDwpjE"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "import json\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "from datasets import load_dataset\n",
        "from transformers import ViTForImageClassification, ViTImageProcessor, TrainingArguments, Trainer\n",
        "from peft import LoraConfig, get_peft_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-KD3AqB2gJv"
      },
      "outputs": [],
      "source": [
        "class_names = [\n",
        "    \"Uhud-Martyrs-Square\",\n",
        "    \"Uhud-mounten\",\n",
        "    \"Ghars-Well\",\n",
        "    \"Quba-Mosque\",\n",
        "    \"The-Prophet's-Mosque\",\n",
        "    \"Urwah-Ibn-Az-Zubayr-Palace\"\n",
        "]\n",
        "label2id = {name: i for i, name in enumerate(class_names)}\n",
        "id2label = {i: name for i, name in enumerate(class_names)}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oWAa7PV82gXS"
      },
      "outputs": [],
      "source": [
        "print(label2id)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KyvOSP4H2xg5"
      },
      "outputs": [],
      "source": [
        "data_url = \"https://github.com/Afra17/BootCamp_Sdaia_DL_W4/raw/7a803578a580ef2a14b4e2d44da51ae54f29e5fe/dataset_small%20(1).zip\"\n",
        "!wget \"{data_url}\" -O data.zip\n",
        "!unzip -q data.zip -d /content/dataset_files\n",
        "\n",
        "print(\"DONE\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_dir = \"/content/dataset_files\"\n",
        "dataset = load_dataset(\"imagefolder\", data_dir=image_dir, split=\"train\")"
      ],
      "metadata": {
        "id": "ODBnJNqHvRtf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJRRGThR4u8V"
      },
      "outputs": [],
      "source": [
        "def add_labels(example):\n",
        "    path = example['image'].filename if hasattr(example['image'], 'filename') else \"\"\n",
        "    example['labels'] = 0\n",
        "    for i, name in enumerate(class_names):\n",
        "        if name in path:\n",
        "            example['labels'] = i\n",
        "            break\n",
        "    return example\n",
        "\n",
        "dataset = dataset.map(add_labels)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset"
      ],
      "metadata": {
        "id": "jZcnwlGwPbst"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Split Datasets to two (small-large)**"
      ],
      "metadata": {
        "id": "OSvxfrZaNIzY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "main_split = dataset.train_test_split(test_size=0.3, seed=42)\n",
        "large_raw_data = main_split[\"train\"]\n",
        "small_raw_data = main_split[\"test\"]"
      ],
      "metadata": {
        "id": "sFBMVRi2NHUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "large_splits = large_raw_data.train_test_split(test_size=0.2, seed=42)\n",
        "large_train_raw = large_splits[\"train\"]\n",
        "large_test_raw  = large_splits[\"test\"]\n",
        "\n",
        "small_splits = small_raw_data.train_test_split(test_size=0.2, seed=42)\n",
        "small_train_raw = small_splits[\"train\"]\n",
        "small_test_raw  = small_splits[\"test\"]"
      ],
      "metadata": {
        "id": "UrC-DGtFNlBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "large_splits"
      ],
      "metadata": {
        "id": "OAxOaxTAOlKa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g5Qn9syL5cvh"
      },
      "outputs": [],
      "source": [
        "def transform_fn(examples):\n",
        "    examples[\"pixel_values\"] = [\n",
        "        augmentation_transforms(img.convert(\"RGB\")) for img in examples[\"image\"]\n",
        "    ]\n",
        "\n",
        "    if \"label\" in examples:\n",
        "        examples[\"labels\"] = examples[\"label\"]\n",
        "    output_columns = [\"pixel_values\", \"labels\"]\n",
        "    return {k: examples[k] for k in output_columns if k in examples}\n",
        "\n",
        "large_train = large_train_raw.with_transform(transform_fn)\n",
        "large_test  = large_test_raw.with_transform(transform_fn)\n",
        "\n",
        "\n",
        "small_train = small_train_raw.with_transform(transform_fn)\n",
        "small_test  = small_test_raw.with_transform(transform_fn)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "unique_labels = sorted(list(set(main_split[\"train\"][\"labels\"])))\n",
        "num_classes = len(unique_labels)\n",
        "\n",
        "cols = 3\n",
        "rows = (num_classes // cols) + (1 if num_classes % cols != 0 else 0)\n",
        "plt.figure(figsize=(15, rows * 5))\n",
        "\n",
        "for i, label_id in enumerate(unique_labels):\n",
        "    idx = main_split[\"train\"][\"labels\"].index(label_id)\n",
        "\n",
        "    raw_sample = main_split[\"train\"][idx]\n",
        "\n",
        "    img = raw_sample[\"image\"]\n",
        "    class_name = id2label[label_id]\n",
        "\n",
        "    plt.subplot(rows, cols, i + 1)\n",
        "    plt.imshow(img)\n",
        "    plt.title(f\"Class: {class_name}\\n(Original Image)\", fontsize=12, fontweight='bold')\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XPRIwyFlODDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Do Augmentation**"
      ],
      "metadata": {
        "id": "tKl0KDTHP8Vh"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VkayeUHI2xp4"
      },
      "outputs": [],
      "source": [
        "augmentation_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(15),\n",
        "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I_K8XNR660zD"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "example = large_train[5]\n",
        "\n",
        "image_data = example[\"pixel_values\"]\n",
        "\n",
        "# 3. Display it\n",
        "plt.imshow(image_data.permute(1, 2, 0) if hasattr(image_data, 'permute') else image_data)\n",
        "plt.title(\"Augmented Image\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **MODEL \"Vision Transformer\"**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GWFfoY3KN0fy"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "US3HL-pJ6-pb"
      },
      "outputs": [],
      "source": [
        "model_id = \"google/vit-base-patch16-224-in21k\"\n",
        "processor = ViTImageProcessor.from_pretrained(model_id)\n",
        "\n",
        "model = ViTForImageClassification.from_pretrained(\n",
        "    model_id,\n",
        "    num_labels=len(class_names),\n",
        "    id2label=id2label,\n",
        "    label2id=label2id\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Full Fine-Tuning (Samll- large dataset)**"
      ],
      "metadata": {
        "id": "QnnoUp3QQMtG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Large Datasets**"
      ],
      "metadata": {
        "id": "Q17j38aUQlF-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate"
      ],
      "metadata": {
        "id": "IChUBAAwTGQU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./vit-full-finetune\",\n",
        "    per_device_train_batch_size=8,\n",
        "    learning_rate=2e-5,\n",
        "    num_train_epochs=15,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    remove_unused_columns=False,\n",
        "    logging_steps=1,\n",
        "    report_to=\"none\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "PDUfaa8mTO9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import evaluate\n",
        "metric = evaluate.load(\"accuracy\")\n",
        "def compute_metrics(eval_pred):\n",
        "\n",
        "    logits, labels = eval_pred\n",
        "\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "\n",
        "    return metric.compute(predictions=predictions, references=labels)"
      ],
      "metadata": {
        "id": "iWrhzINtSzF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=large_train,\n",
        "    eval_dataset=large_test,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "LK-qzKJhTtzb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# train_loss: 0.6378657621996743\n",
        "# Accuracy=0.769231\n",
        "-----\n",
        "# train_runtime': 244.4977s\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "3LGQsAi-VncO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Small Datasets**"
      ],
      "metadata": {
        "id": "oqSvFMCbT2b1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=small_train,\n",
        "    eval_dataset=small_test,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "QX1LqGAHQVQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# training_loss=0.8075989776187473,\n",
        "# Accuracy=0.833333\n",
        "\n",
        "------\n",
        "# train_runtime': 153.6173s"
      ],
      "metadata": {
        "id": "K7TB3k5gWfhg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " # **Perform Parameter Efficient Fine-Tuning (PEFT) by LORA**"
      ],
      "metadata": {
        "id": "S2PuzN1mVtQf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_KyuIJa7EkL"
      },
      "outputs": [],
      "source": [
        "lora_config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=16,\n",
        "    target_modules=[\"query\", \"value\"],\n",
        "    lora_dropout=0.1,\n",
        "    modules_to_save=[\"classifier\"]\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, lora_config)\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n",
        "model.print_trainable_parameters()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cCPuW07A7LrG"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./medina-vit-lora-final\",\n",
        "    remove_unused_columns=False,\n",
        "    per_device_train_batch_size=4,\n",
        "    gradient_accumulation_steps=1,\n",
        "    learning_rate=1e-3,\n",
        "    num_train_epochs=30,\n",
        "    logging_steps=5,\n",
        "    save_strategy=\"epoch\",\n",
        "    fp16=True if device == \"cuda\" else False,\n",
        "    report_to=\"none\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Large Datasets**"
      ],
      "metadata": {
        "id": "mfXxwXnrYFqM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yv5zlSi57L14"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "    return {\n",
        "        'pixel_values': torch.stack([x['pixel_values'] for x in batch]),\n",
        "        'labels': torch.tensor([x['labels'] for x in batch])\n",
        "    }\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=large_train,\n",
        "    eval_dataset=large_test,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# training_loss=0.02864039983504858\n",
        "-----\n",
        "# train_runtime: 110.2336s\n"
      ],
      "metadata": {
        "id": "PuDuO5Hlcrsx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Small Datasets**"
      ],
      "metadata": {
        "id": "6RgE2oDQYO8J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=small_train,\n",
        "    eval_dataset=small_test,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "TSi6rzZmYQfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# training_loss=0.0009836134015737722\n",
        "-----\n",
        "# train_runtime: 15.287s"
      ],
      "metadata": {
        "id": "Vx34BNGJy2R1"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "private_outputs": true,
      "cell_execution_strategy": "setup",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}